{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RMkjAdXQxW1v"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H88fNCXQwTsr"
      },
      "outputs": [],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Onea4skFxNSE"
      },
      "source": [
        "### Preparing training data\n",
        "The training data is composed of pairs (x<sub>1</sub>, x<sub>2</sub>) so that x<sub>2</sub> consists of the value of the sine of x<sub>1</sub> for x<sub>2</sub> in the interval from 0 to 2π \\\n",
        "(0 to 2π so that the sin wave is complete)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Rj1N4Z6WxCR4"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.manual_seed(111)\n",
        "train_data_length = 1024\n",
        "\n",
        "train_data = torch.zeros((train_data_length, 2))\n",
        "train_data[:, 0] = 2 * math.pi * torch.rand(train_data_length)\n",
        "train_data[:, 1] = torch.sin(train_data[:, 0])\n",
        "\n",
        "train_labels = torch.zeros(train_data_length)\n",
        "train_set = [(train_data[i], train_labels[i]) for i in range(train_data_length)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "17BWoGd4xKMO",
        "outputId": "ac6fa291-e664-44f2-fa34-fc3d669a8a06"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_data[:, 0], train_data[:, 1], \".\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-PZYxjm1u1s"
      },
      "source": [
        "### Preparing training and testing samples for the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JTlDMGiTy_NW"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True) # Training Data\n",
        "latent_space_samples = torch.randn(train_data_length, 2) # Testing Data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "72QMjKR5ztsP"
      },
      "source": [
        "### Implementing the Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "C6be4vUlzM_4"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "      nn.Linear(2, 256),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.3),\n",
        "      nn.Linear(256, 128),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.3),\n",
        "      nn.Linear(128, 64),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.3),\n",
        "      nn.Linear(64, 1),\n",
        "      nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.model(x)\n",
        "    return output\n",
        "\n",
        "discriminator = Discriminator()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4wP37Y0HzqQF"
      },
      "source": [
        "### Implementing the Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uxbe9d1fzlWT"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(2, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.model(x)\n",
        "        return output\n",
        "\n",
        "generator = Generator()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ed6m_2m6ACJ7"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "yh1lX8q9z2Yt",
        "outputId": "fb9a255b-9bee-45ce-871b-de9cc758ec72"
      },
      "outputs": [],
      "source": [
        "from time import sleep\n",
        "from IPython.display import clear_output\n",
        "\n",
        "lr = 0.0001\n",
        "num_epochs = 500\n",
        "loss_function = nn.BCELoss()\n",
        "\n",
        "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
        "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)\n",
        "\n",
        "loss_values = \"\"\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "  for n, (real_samples, _) in enumerate(train_loader):\n",
        "    # Data for training the discriminator\n",
        "    real_samples_labels = torch.ones((batch_size, 1))\n",
        "    latent_space_samples = torch.randn((batch_size, 2))\n",
        "    generated_samples = generator(latent_space_samples)\n",
        "    generated_samples_labels = torch.zeros((batch_size, 1))\n",
        "\n",
        "    all_samples = torch.cat((real_samples, generated_samples))\n",
        "    all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels))\n",
        "\n",
        "    # Training the discriminator\n",
        "    discriminator.zero_grad()\n",
        "    output_discriminator = discriminator(all_samples)\n",
        "    \n",
        "    # Discriminator loss\n",
        "    loss_discriminator = loss_function(output_discriminator, all_samples_labels)\n",
        "    loss_discriminator.backward()\n",
        "    optimizer_discriminator.step()\n",
        "\n",
        "    # Data for training the generator\n",
        "    latent_space_samples = torch.randn((batch_size, 2))\n",
        "\n",
        "    # Training the generator\n",
        "    generator.zero_grad()\n",
        "    generated_samples = generator(latent_space_samples)\n",
        "    output_discriminator_generated = discriminator(generated_samples)\n",
        "\n",
        "    # Generator loss\n",
        "    loss_generator = loss_function(output_discriminator_generated, real_samples_labels)\n",
        "    loss_generator.backward()\n",
        "    optimizer_generator.step()\n",
        "\n",
        "    # Show loss and visualize the outputs\n",
        "    if (epoch % 5 == 0) and (n == batch_size - 1):\n",
        "      clear_output(wait=True)\n",
        "      loss_values += f\"Epoch: {epoch} Loss in D.: {loss_discriminator}\\n\" + f\"Epoch: {epoch} Loss in G.: {loss_generator}\\n\" + \"--------------------\\n\"\n",
        "      generated_samples = generated_samples.detach() # converts into a normal tensor (which can be converted to numpy)\n",
        "      plt.title(f\"Output of Generator at epoch: {epoch}\")\n",
        "      plt.plot(generated_samples[:, 0], generated_samples[:, 1], \".\")\n",
        "      plt.show()\n",
        "      sleep(0.1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zDhlyKmG0g-d"
      },
      "source": [
        "### Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "284dzWgy0jwR",
        "outputId": "626c0a49-2e9e-4c1c-d0da-c1d9bd228e79"
      },
      "outputs": [],
      "source": [
        "# Loss at various epochs\n",
        "print(loss_values)\n",
        "\n",
        "latent_space_samples = torch.randn(train_data_length, 2)\n",
        "generated_samples = generator(latent_space_samples)\n",
        "\n",
        "generated_samples = generated_samples.detach()\n",
        "plt.plot(generated_samples[:, 0], generated_samples[:, 1], \".\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UoEWAOs5AFub"
      },
      "source": [
        "### How GAN learns:\n",
        "<img src=\"./GAN training 500 epochs.gif\" alt=\"GAN training 500 epochs\">"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
